<!DOCTYPE html>
<!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Fri Jul 24 2020 21:59:59 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="5ed917aa461e364256bc9ca5" data-wf-site="5ed917aa5479ed4332e1261d">
<head>
  <meta charset="utf-8">
  <title>Object Localization and Identification in Maritime Domain</title>
  <meta content="Object Localization and Identification in Maritime Domain" property="og:title">
  <meta content="Object Localization and Identification in Maritime Domain" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="../css/normalize.css" rel="stylesheet" type="text/css">
  <link href="../css/webflow.css" rel="stylesheet" type="text/css">
  <link href="../css/bens-marvelous-project-0464a7.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="../images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="../images/webclip.png" rel="apple-touch-icon">
</head>
<body>
  <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navigation w-nav">
    <div class="navigation-wrap"><a href="../index.html" class="logo-link w-nav-brand"><img src="../images/data-lab-final-maroon.png" width="122" srcset="../images/data-lab-final-maroon-p-500.png 500w, ../images/data-lab-final-maroon-p-800.png 800w, ../images/data-lab-final-maroon-p-1080.png 1080w, ../images/data-lab-final-maroon.png 1280w" sizes="(max-width: 479px) 100vw, 122px" alt="" class="logo-image"></a>
      <div class="menu">
        <nav role="navigation" class="navigation-items w-nav-menu"><a href="../about.html" class="navigation-item w-nav-link">About</a><a href="../projects-overview.html" class="navigation-item w-nav-link">RESEARCH</a><a href="../news.html" class="navigation-item w-nav-link">NEWS</a><a href="../contact.html" class="navigation-item w-nav-link">Contact</a></nav>
        <div class="menu-button w-nav-button"><img src="../images/menu-icon_1menu-icon.png" width="22" alt="" class="menu-icon"></div>
      </div>
      <a href="mailto:jtesic@txstate.edu?subject=DataLab%20Inquiry" class="button cc-contact-us w-inline-block">
        <div>Contact US</div>
      </a>
    </div>
  </div>
  <div class="section cc-home-wrap">
    <div class="project-overview-header project2">
      <div class="intro-content">
        <div class="heading-jumbo heading-project-1">Object Localization and Identification in Maritime Domain<br></div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="w-container">
      <h2 class="heading-5"><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11006/1100616/Identifying-maritime-vessels-at-multiple-levels-of-descriptions-using-deep/10.1117/12.2519248.short?SSO=1" target="_blank">Identifying Maritime Vessels at Multiple Levels of Descriptions using Deep Features</a></h2>
    </div>
    <div class="container">
      <div class="w-layout-grid project-details-grid">
        <div id="w-node-27f88a387918-56bc9ca5">
          <div class="details-wrap">
            <div class="label">Faculty</div>
            <div class="paragraph-light"> Jelena Tešić </div>
          </div>
          <div class="details-wrap">
            <div class="label">Students</div>
            <div class="paragraph-light">David Bo Heyse <br>Nicholas Warren</div>
          </div>
          <div class="details-wrap">
            <div class="label"><a href="#https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11006/1100616/Identifying-maritime-vessels-at-multiple-levels-of-descriptions-using-deep/10.1117/12.2519248.short?SSO=1">Link to Paper</a></div>
          </div>
        </div>
        <div>
          <div class="label">Abstract</div>
          <div class="paragraph-light">Varying resolution quality of operational data, size of targets, view occlusions, and large variation in sensors due to nature of overhead systems as compared to consumer devices contribute to degradation of the maritime vessel identification. We exploit the maritime domain characteristics to optimize and refine the deep learning Mask-RCNN framework for training generic maritime vessel classes. Maritime domain, compared to consumer domain, lack alternative targets that would be incorrectly associated as maritime vehicles: this allows us to relax the parameter constraints learned on urban natural scenes in consumer photos, adjust parameters of the model inference, and achieve robust performance and high AP measure for transfer learning scenarios. In this paper, we build upon this robust localization work, and extend our transfer learning work to new domains and datasets. We propose new approach for identifying specific category of maritime vessels and build a refined multi-label classifier that is based on deep Mask-RCNN features. The classifier is designed to be robust to domain transfer (e.g. different overhead maritime video feed), and to the noise in the data annotation (e.g. vessel is not correctly marked or label is ambiguous). We demonstrate superior category classification results of this low shot learning approach on publicly available MarDCT dataset.</div>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="div-block-8"><a href="#" class="lightbox-link-2 w-inline-block w-lightbox"><img src="../images/Screenshot-from-2019-02-11-19-00-45.png" srcset="../images/Screenshot-from-2019-02-11-19-00-45-p-500.png 500w, ../images/Screenshot-from-2019-02-11-19-00-45-p-800.png 800w, ../images/Screenshot-from-2019-02-11-19-00-45-p-1080.png 1080w, ../images/Screenshot-from-2019-02-11-19-00-45-p-1600.png 1600w, ../images/Screenshot-from-2019-02-11-19-00-45.png 2213w" sizes="(max-width: 479px) 100vw, (max-width: 767px) 48vw, (max-width: 991px) 37vw, 41vw" alt="" class="image-7"><script type="application/json" class="w-json">{
  "items": [
    {
      "width": 2213,
      "caption": "",
      "height": 1331,
      "fileName": "5ef23e4e46a970574cc5f304_Screenshot from 2019-02-11 19-00-45.png",
      "origFileName": "Screenshot from 2019-02-11 19-00-45.png",
      "url": "../images/Screenshot-from-2019-02-11-19-00-45.png",
      "_id": "5ef23e4e46a970574cc5f304",
      "type": "image",
      "fileSize": 1916740
    },
    {
      "width": 1400,
      "caption": "",
      "height": 824,
      "fileName": "5ef23e5f4040f08bb5769ea6_poly2.png",
      "origFileName": "poly2.png",
      "url": "../images/poly2.png",
      "_id": "5ef23e5f4040f08bb5769ea6",
      "type": "image",
      "fileSize": 1058862
    }
  ]
}</script></a></div>
    </div>
  </div>
  <div class="section">
    <div class="w-container">
      <h2 class="heading-5"><a href="#https://ieeexplore.ieee.org/abstract/document/8537839">Transfer learning of deep neural networks for visual collaborative maritime asset identification</a></h2>
    </div>
    <div class="container">
      <div class="w-layout-grid project-details-grid">
        <div id="w-node-235a5ba7d116-56bc9ca5">
          <div class="details-wrap">
            <div class="label">Faculty</div>
            <div class="paragraph-light">Jelena Tešić</div>
          </div>
          <div class="details-wrap">
            <div class="label">Students</div>
            <div class="paragraph-light">Nicholas Warren <br>Benjamin Garrard <br>Elliot Staudt</div>
          </div>
          <div class="details-wrap">
            <div class="label"><a href="#https://ieeexplore.ieee.org/abstract/document/8537839">Link to paper</a></div>
          </div>
        </div>
        <div>
          <div class="label">Abstract</div>
          <div class="paragraph-light"><strong> </strong>Recent advances in deep learning for visual recognition demonstrate high performing pipeline for building and deploying well-performing content models. These advances come with underlying assumptions of the data characteristics pertaining to consumer image and video and availability of the large set of annotated data. In this paper we show how to apply lessons learned in the consumer domain to overhead maritime video corpora. We present how to successfully tune deep learning network to overhead maritime domain and tune parameters to new domain characteristics to achieve high performance metric with smaller set of domain annotations. This approach improves the state-of-the-art metric by 80% on maritime IPATCH data. Next, we present challenges and propose several approaches on user collaboration for maritime asset identification, and introduce the notion of persistent and intermittent models.</div>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="div-block-8"><a href="#" class="lightbox-link-2 w-inline-block w-lightbox"><img src="../images/poly1.png" srcset="../images/poly1-p-500.png 500w, ../images/poly1-p-800.png 800w, ../images/poly1-p-1080.png 1080w, ../images/poly1.png 1400w" sizes="(max-width: 479px) 100vw, (max-width: 767px) 48vw, (max-width: 991px) 37vw, 41vw" alt="" class="image-7"><script type="application/json" class="w-json">{
  "items": [
    {
      "width": 1400,
      "caption": "",
      "height": 824,
      "fileName": "5ef23e3abd110689b938b961_poly1.png",
      "origFileName": "poly1.png",
      "url": "../images/poly1.png",
      "_id": "5ef23e3abd110689b938b961",
      "type": "image",
      "fileSize": 1448749
    },
    {
      "width": 1909,
      "caption": "",
      "height": 804,
      "fileName": "tanker.png",
      "origFileName": "tanker.png",
      "url": "../images/tanker.png",
      "_id": "5ee6910b66757f0fcd41a3d5",
      "type": "image",
      "fileSize": 576694
    }
  ]
}</script></a></div>
    </div>
  </div>
  <div class="section">
    <div class="section">
      <div class="w-container">
        <h2 class="heading-5"><a href="#" target="_blank">Aerial View Object Classification using Deep Learning</a></h2>
      </div>
      <div class="container">
        <div class="w-layout-grid project-details-grid">
          <div id="w-node-3c607fdc17a1-56bc9ca5">
            <div class="details-wrap">
              <div class="label">Faculty</div>
              <div class="paragraph-light"> Jelena Tešić </div>
            </div>
          </div>
          <div>
            <div class="label">Abstract</div>
            <div class="paragraph-light">Geospatial analysis is the process of manipulating geographic data as it pertains to terrain, topology, geomorphology, temporal locality, and history, and applying such data against a geographic model to infer upon or better understand an objective reality. Applications of geospatial analysis include, but are not limited to, land use and storm water management, emissions assessment of municipal landfills, preconstruction planning of new development with a focus on graceful spatial integration. Given the broad spectrum of use cases and needs for such a form of analysis, it is imperative that the acquisition and logical ordering of geographic data be streamlined and economical for all entities in need of such data. We have addressed the following aspects of this challenge: 1. Transform ArcGIS annotations into object detection compatible training format 2. Deep learning framework for detecting objects in overhead imagery 3. Object Identification on edge: MaskRCNN on NVIDIA Jetson TX2</div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="section">
      <div class="container">
        <div class="div-block-12">
          <h2 class="heading-13">Alumni</h2>
        </div>
        <div>
          <ul role="list" class="list-3 w-list-unstyled">
            <li class="list-item-6">Nicholas Warren<br>B.Sc. Dec 2019 </li>
            <li class="list-item-6">David Bo Heyse <br>B.Sc. Dec 2019(USAA)</li>
            <li class="list-item-7">Brent Redmon <br>NSF REU 2019</li>
            <li class="list-item-8">Constance Xu, <br>NSF REU 2019</li>
            <li class="list-item-9">Daniel Le, <br>B.Sc. May 2020 (DoD)</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
  <div class="section cc-cta">
    <div class="container cta-image">
      <div class="cta-wrap">
        <div class="div-block mobile-scale">
          <div class="cta-text">
            <div class="heading-jumbo-small-home cta-text">Give us your data!<br></div>
            <div class="paragraph-bigger cta-light">Now more than ever, we are looking to test our algorithm on various real world data.<br></div>
          </div>
          <a href="../contact.html" class="button cc-jumbo-button w-inline-block">
            <div>Donate Data</div>
          </a>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="footer-wrap"><a href="https://github.com/DataLab12" target="_blank" class="github-link w-inline-block"><img src="../images/GitHub-Mark-32px.png" width="15" alt="" class="webflow-logo-tiny"><div class="paragraph-tiny">Our Github</div></a></div>
    </div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.4.1.min.220afd743d.js?site=5ed917aa5479ed4332e1261d" type="text/javascript" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
  <script src="../js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>